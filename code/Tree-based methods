#5.Dicision Tree
#5.1 Decision Tree via Gini index
dt_model<-rpart(formula=quality.code~., data=train_set, method="class", parms=list(split= "gini"),
  control=rpart.control(maxdepth=5, minsplit= 20, minbucket=10, cp= 0.001,maxsurrogate= 0))

#Select the optimal cp and prune according to the cross-validation results
best_cp <- dt_model$cptable[which.min(dt_model$cptable[,"xerror"]), "CP"]
dt_pruned <- prune(dt_model, cp = best_cp)

cp_tab <-as.data.frame(dt_model$cptable)
cp_tab$TreeSize<-cp_tab$nsplit+1

#Compute accuracy on training and test sets for each CP
train_acc<-sapply(cp_tab$CP, function(cp_val){
  pruned<- prune(dt_model, cp=cp_val)
  mean(predict(pruned, train_set, type="class")==train_set$quality.code)
})
test_acc<-sapply(cp_tab$CP, function(cp_val){
  pruned<-prune(dt_model, cp=cp_val)
  mean(predict(pruned, test_set, type="class")== test_set$quality.code)
})

#10-fold cv to select the parameter conbination
ctrl<-trainControl(method= "cv", number=10)
grid<-data.frame(cp=cp_tab$CP)

cv_fit <- train(quality.code ~ ., data=train_set, method="rpart", trControl=ctrl, 
                tuneGrid=grid,parms=list(split="gini"), 
                control=rpart.control(maxdepth=19, minspli=5,minbucket=3, cp=0.001,maxsurrogate= 0))
cv_results<-cv_fit$results
cv_acc<-cv_results$Accuracy[match(cp_tab$CP,cv_results$cp)]

df<-data.frame(TreeSize=cp_tab$TreeSize,Training=train_acc,
               CrossValidation=cv_acc,Test=test_acc)

df_long<-reshape2::melt(df, id.vars="TreeSize",
  variable.name="Dataset",value.name="Accuracy")

ggplot(df_long, aes(x=TreeSize, y=Accuracy, color=Dataset)) +
  geom_line(size=1) +geom_point(size=3) +
  scale_x_continuous(breaks=df$TreeSize) +scale_y_continuous(labels=percent_format(accuracy= 1)) +
  scale_color_manual(values=c(Training="#1f78b4", CrossValidation="#33a02c", Test="#ff7f00"))+
  labs(title= "Accuracy Comparison Across Tree Sizes",
      subtitle=sprintf("Optimal Pruning CP = %.5f (MaxDepth = %d, MinSplit = %d)",
      cp_tab$CP[which.max(cv_acc)], dt_model$control$maxdepth, dt_model$control$minsplit),
      x="Number of Leaf Nodes (Tree Size)", y="Accuracy", color =NULL)+
  theme_minimal(base_family ="Arial") +
  theme(
    plot.title= element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle=element_text(size = 11, color = "gray40", hjust = 0.5),
    axis.title=element_text(size = 12),
    axis.text=element_text(size = 10),
    legend.position=c(0.8, 0.2),
    legend.background=element_rect(fill = alpha("white", 0.6), color = NA),
    panel.grid.major=element_line(color = "gray90"),
    panel.grid.minor=element_blank())

#Visualize the tree structure before and after pruning
par(mar=c(1, 1, 2, 1))
rpart.plot(dt_model,main= "Original Tree",type=2,extra=104,fallen.leaves=TRUE,uniform=TRUE, 
           cex=NULL,tweak=1.3,split.cex=1.3,under.cex=1,xcompact=FALSE,ycompact=FALSE)
rpart.plot(dt_pruned, main="Tree after pruning", type=2, extra=104,
           fallen.leaves=TRUE, uniform=TRUE, cex=NULL,tweak=1.1,
           split.cex=1.3, under.cex=1, xcompact= FALSE, ycompact=FALSE)

#Predict on the test set
pred_class<-predict(dt_pruned,test_set, type ="class")
pred_prob<-predict(dt_pruned, test_set,type="prob")[,2] 

dt_roc <- roc(response=test_set$quality.code,predictor=pred_prob,
              levels=c("0","1"),direction = "<")
dt_auc<-auc(dt_roc)
roc_df<-data.frame(
  Model = "Decision Tree",
  FPR=1-dt_roc$specificities,
  TPR=dt_roc$sensitivities
)

#ROC curve
ggplot(roc_df, aes(x=FPR, y=TPR, color=Model)) +
  geom_line(size =0.7) +
  geom_abline(intercept=0, slope =1, linetype="dashed", color="gray") +
  labs(title="ROC Curve for Decision Tree", subtitle=paste("AUC =", round(dt_auc, 4)),
       x="False Positive Rate (FPR)",y="True Positive Rate (TPR)")+
  theme_minimal() +
  scale_color_manual(values = "#377EB8")+
  theme(legend.position="none",plot.title=element_text(face= "bold", size=16, hjust=0.5),
    plot.subtitle=element_text(size=12, hjust =0.5),axis.title=element_text(size=12))

cm_dt<-table(Predicted = pred_class, Actual = test_set$quality.code)
print(cm_dt)
tp<-cm_dt[2,2]
tn<-cm_dt[1,1]
fp<-cm_dt[2,1]
fn<-cm_dt[1,2]
metrics<-c(
  Accuracy=(tp+tn)/sum(cm_dt),
  Precision=tp/(tp+fp),
  Recall=tp/ (tp+ fn),
  Specificity= tn/(tn +fp),
  FPR=fp/(fp+tn),
  F1= 2*tp/(2*tp+fp+fn))
print(round(metrics, 4))

#Scatter plot
top2<-names(sort(dt_model$variable.importance, decreasing=TRUE))[1:2]
feat1<-top2[1]
feat2<-top2[2]

splits<-dt_model$splits
cut1<- splits[rownames(splits)==feat1, "index"][1]
cut2<-splits[rownames(splits)==feat2, "index"][1]

xrng<-range(test_set[[feat1]],na.rm=TRUE)
yrng<-range(test_set[[feat2]], na.rm=TRUE)

ggplot(test_set, aes_string(x=feat1, y=feat2, color="factor(quality.code)")) +
  geom_point(alpha=0.6, size=2) +
  geom_vline(xintercept=cut1, color= "darkgreen", size = 1) +
  geom_segment(x=xrng[1],xend =cut1,y=cut2,yend=cut2,color="darkgreen",size= 1)+
  annotate("text",x=mean(c(cut1, xrng[2])),y=yrng[1],label ="R1",
           vjust=-1, size=6, fontface="bold")+
  annotate("text",x=mean(c(xrng[1], cut1)),y=yrng[1],label ="R2",
           vjust=-1, size=6, fontface="bold") +
  annotate("text",x=mean(c(xrng[1], cut1)),y=yrng[2],label ="R3",
           vjust=1, size=6, fontface="bold")+
  scale_color_manual(values = c("0" = "#1f78b4", "1" = "#e31a1c")) +
  labs(title="Decision Regions",
    subtitle=sprintf("%s < %.3f    %s < %.3f", feat1, cut1, feat2, cut2),
    x=feat1, y=feat2, color="Quality")+
  theme_minimal()+
  theme(plot.title=element_text(size=16, face="bold", hjust=0.5),
    plot.subtitle=element_text(size=11, color="gray40", hjust=0.5))





#5.2 Decision Tree via Generalized Gini index
#Define the loss matrix
loss_mat<- matrix(
  c(0, 2,    
    1, 0),     
  nrow=2, byrow = TRUE,
  dimnames=list(pred= c("0","1"),
                true=c("0","1"))
)


#5.2 Decision Tree via Generalized Gini index
#Define the loss matrix
loss_mat<- matrix(
  c(0, 1.7,    
    1, 0),     
  nrow=2, byrow = TRUE,
  dimnames=list(pred= c("0","1"),
                true=c("0","1"))
)

# 2. Build the original decision tree via Generalized Gini index
dt_gen <-rpart(quality.code ~ ., data=train_set,method="class",
               parms=list(split="gini",loss=loss_mat),
               control= rpart.control(maxdepth=5, minsplit=20, minbucket=10, cp=0.001, maxsurrogate= 0))

best_cp_gen<-dt_gen$cptable[ which.min(dt_gen$cptable[,"xerror"]), "CP" ]
dt_pruned_gen<-prune(dt_gen, cp = best_cp_gen)
pred_class<-predict(dt_pruned_gen, test_set, type="class")
pred_prob<-predict(dt_pruned_gen,test_set, type="prob")[, "1"]

cm_dt_gen<-table(Pred=pred_class, True=test_set$quality.code)
print(cm_dt_gen)

tp_dt_gen <-cm_dt_gen["1","1"]
tn_dt_gen<-cm_dt_gen["0","0"]
fp_dt_gen<-cm_dt_gen["1","0"]
fn_dt_gen<-cm_dt_gen["0","1"]
metrics_dt_gen <- c(
  Accuracy=(tp_dt_gen+tn_dt_gen)/sum(cm_dt_gen),
  Precision=tp_dt_gen/(tp_dt_gen+fp_dt_gen),
  Recall=tp_dt_gen/(tp_dt_gen+fn_dt_gen),
  Specificity=tn_dt_gen/(tn_dt_gen+fp_dt_gen),
  NPV = tn_dt_gen / (tn_dt_gen + fn_dt_gen),
  F1=2*tp_dt_gen/(2*tp_dt_gen+fp_dt_gen+fn_dt_gen))
print(round(metrics_dt_gen, 4))

#Scatter plot
top2_gen<-names(sort(dt_gen$variable.importance, decreasing=TRUE))[1:2]
print(sort(dt_gen$variable.importance, decreasing=TRUE))
feat1_gen<-top2_gen[1]
feat2_gen<-top2_gen[2]

splits_gen<-dt_gen$splits
cut1_gen<- splits_gen[rownames(splits_gen)==feat1_gen, "index"][1]
cut2_gen<-splits_gen[rownames(splits_gen)==feat2_gen, "index"][1]

xrng_gen<-range(test_set[[feat1_gen]],na.rm=TRUE)
yrng_gen<-range(test_set[[feat2_gen]], na.rm=TRUE)

ggplot(test_set, aes_string(x =feat1_gen, y=feat2_gen, color="quality.code"))+
  geom_point(alpha=0.6, size=2)+
  geom_vline(xintercept =cut1_gen, color="darkgreen", size=1)+
  geom_segment(x =xrng_gen[1],xend=cut1_gen,y=cut2_gen, yend=cut2_gen,
               color="darkgreen", size=1) +
  annotate("text",x=mean(c(cut1_gen, xrng_gen[2])), y= yrng_gen[1],
           label="R1", vjust =-1, size=6, fontface="bold")+
  annotate("text", x=mean(c(xrng_gen[1],cut1_gen)), y=yrng_gen[1],
           label="R2", vjust=-1, size=6, fontface="bold")+
  annotate("text", x=mean(c(xrng_gen[1],cut1_gen)), y=yrng_gen[2],
           label="R3", vjust=1, size=6, fontface ="bold") +
  labs(title="Decision Regions via Generalized Gini Index",
       subtitle = sprintf("%s < %.3f    %s < %.3f",feat1_gen, cut1_gen, feat2_gen, cut2_gen),
       x=feat1_gen, y=feat2_gen, color="Quality") +
  theme_minimal()+
  theme(plot.title= element_text(size=16, face="bold", hjust=0.5),
        plot.subtitle=element_text(size=11, color="gray40", hjust=0.5)
  )


#6.Bagging
ctrl<-trainControl(method = "cv", number= 10)
par_bag<-rpart::rpart.control(maxdepth=5, minsplit=20,
                              minbucket=10, cp=0.001, maxsurrogate= 0)

bag_model<-train(quality.code ~ ., data=train_set, method="treebag", 
                 trControl=ctrl,metric="Accuracy", control=par_bag)
print(bag_model)
bag_pred <- predict(bag_model, test_set)
cm_bag <- confusionMatrix(bag_pred, test_set$quality.code, positive = "1")
print(cm_bag)


#1.Feature split frequency statistics
trees_bag <- purrr::map(bag_model$finalModel$mtrees, "btree")
split_vars_bag <- purrr::map(trees_bag, ~ .x$frame$var[.x$frame$var != "<leaf>"]) %>%
  unlist()
split_freq_bag <- as.data.frame(table(split_vars_bag)) %>% arrange(desc(Freq))

ggplot(split_freq_bag, aes(x=reorder(split_vars_bag, -Freq), y=Freq, fill=Freq)) +
  geom_col(width=0.7) +
  geom_text(aes(label=Freq), vjust=-0.5, size=3) +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  labs(title="Split Frequency of Features in Bagging",
    x="Feature", y="Split Count", fill="Count") +
  theme_minimal(base_size=14) +
  theme(
    plot.title=element_text(face="bold", hjust=0.5),
    axis.text.x=element_text(angle=45, hjust=1, face= "bold"),
    axis.title=element_text(face="bold"),
    panel.grid.major=element_line(color="gray90"),
    panel.grid.minor=element_blank()
  )


#2.Calculate the prediction correlation coefficient between trees
tree_preds_list <-lapply(trees_bag, function(tree) {
  predict(tree, newdata=test_set, type="prob")[, "1"]})
preds_mat<-do.call(cbind, tree_preds_list)
colnames(preds_mat)<-paste0("tree_", seq_len(ncol(preds_mat)))
corr_mat<-cor(preds_mat)
mean_corr<- mean(corr_mat[upper.tri(corr_mat)])
cat("Average correlation coefficient: ", round(mean_corr, 3), "\n")


#7.Random Forest
#Modeling
p<-ncol(train_set)- 1
mtry_val<-floor(sqrt(p))

rf_model<-randomForest(
  quality.code ~ .,data= train_set, ntree=200, mtry=mtry_val, importance=TRUE,
  maxnodes=32, nodesize=10)

#print(rf_model)
oob_error<-rf_model$err.rate[nrow(rf_model$err.rate), "OOB"]
cat(sprintf("OOB estimate of error rate: %.2f%%\n", 100*oob_error))

# Predict on the testset
rf_pred_class<-predict(rf_model, newdata=test_set, type="response")
accuracy_rf<-mean(rf_pred_class==test_set$quality.code)
cat(sprintf("Random Forest Accuracy on Test Set: %.2f%%\n", 100*accuracy_rf))

# Confudion matrix
conf_matrix_rf<-table(
  Predicted=rf_pred_class,
  Actual=test_set$quality.code)
cat("Random Forest Confusion Matrix:\n")
print(conf_matrix_rf)



# Hyperparameter Optimization via Grid Search
# parameter space
p       <- ncol(train_set) - 1
m_vals  <- seq(floor(sqrt(p)/2), ceiling(2*sqrt(p))) 
M_vals  <- seq(50, 500, by = 50)                     
grid    <- expand.grid(mtry = m_vals, ntree = M_vals)
grid$F1 <- NA 

folds <- createFolds(train_set$quality.code, k = 5, list = TRUE)

# 5-fold CV for each parameter combination
for (i in seq_len(nrow(grid))) {
  mtry_val<-grid$mtry[i]
  ntree_val<-grid$ntree[i]
  
  f1_scores<-numeric(length(folds))
  for (j in seq_along(folds)) {
    idx_val<-folds[[j]]
    cv_train<-train_set[-idx_val, ]
    cv_valid<-train_set[ idx_val, ]
    
    rf_cv<-randomForest(quality.code ~ ., data= cv_train, mtry=mtry_val, ntree=ntree_val)
    pred_cv <- predict(rf_cv, newdata=cv_valid, type="response")
    f1_scores[j]<- F1_Score(y_pred=pred_cv, y_true= cv_valid$quality.code,
                             positive=levels(train_set$quality.code)[2])
    }
  grid$F1[i]<-mean(f1_scores)
}

# Find optimal parameter
best_idx<- which.max(grid$F1)
best_m<-grid$mtry[best_idx]
best_M<-grid$ntree[best_idx]
best_F1<- grid$F1[best_idx]
cat(sprintf("Best params — mtry = %d, ntree = %d (mean CV-F1 = %.4f)\n",
            best_m, best_M, best_F1))

rf_final<-randomForest(
  quality.code ~ .,
  data=train_set,
  mtry=best_m,
  ntree= best_M,
  importance=TRUE,
  maxnodes=32, nodesize=10)
rf_pred<-predict(rf_final, newdata=test_set, type="response")
cat("Confusion matrix on test set:\n")
print(table(Predicted=rf_pred, Actual=test_set$quality.code))
acc_rf<-mean(rf_pred==test_set$quality.code)
cat(sprintf("Test set accuracy: %.2f%%\n", 100*acc_rf))

#Feature importance
imp<-importance(rf_final)
imp_df <-as.data.frame(imp) %>%
  rownames_to_column(var="Feature") %>%
  select(Feature, MeanDecreaseGini, MeanDecreaseAccuracy) %>%
  pivot_longer(-Feature,names_to="Metric",values_to="Importance") %>%
  group_by(Metric) %>%
  arrange(Importance) %>%
  mutate(Feature=factor(Feature, levels=unique(Feature))) %>%
  ungroup()

ggplot(imp_df, aes(x=Importance, y=Feature, fill=Metric))+
  geom_col(position=position_dodge(width=0.8), width=0.7) +
  facet_wrap(~ Metric, scales="free_x", ncol = 1) +
  scale_fill_manual(values=c("MeanDecreaseAccuracy"="#1b9e77",
                               "MeanDecreaseGini"="#d95f02"))+
  labs(
    title= "Variable Importance in Random Forest",
    subtitle="Comparison of Gini‐based vs. Permutation‐based measures",
    x="Importance",y=NULL, fill= NULL)+
  theme_minimal(base_size=14)+
  theme(
    legend.position="none",
    strip.text=element_text(face="bold", size= 12),
    axis.text.y=element_text(size=11),
    plot.title=element_text(face="bold", size=16, hjust =0.5),
    plot.subtitle=element_text(size=12, hjust=0.5),
    panel.grid.major.y=element_blank()
  )



#8.AdaBoost
ada_grid <- expand.grid(
  iter=c(50, 100, 150),
  maxdepth=5,     
  nu=c(0.05, 0.1, 0.2))

ada_model <- train( quality.code ~ ., data= train_set, method="ada", 
                    trControl=ctrl, tuneGrid=ada_grid, metric ="Accuracy")
print(ada_model)
ada_pred <- predict(ada_model, test_set)
cm_ada <- confusionMatrix(ada_pred, test_set$quality.code, positive = "1")
print(cm_ada)
